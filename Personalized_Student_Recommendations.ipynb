{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB_g-mI5scaS"
      },
      "source": [
        "\n",
        "\n",
        "# > **Importing necessary dependacies**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KEUErGD4ik-l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jcm_wFU9mAK7"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns',None)           #to see all the columns in the dataset in a time\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUe4IaYssk03"
      },
      "source": [
        "**Loading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-_dJFQwZjvwv"
      },
      "outputs": [],
      "source": [
        "url='https://api.jsonserve.com/XgAgFJ'\n",
        "response = requests.get(url)\n",
        "data = response.json()\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMByMxsywUgW"
      },
      "source": [
        "**Eliminating the features that are not relavant to analyse students performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KS2hBPMelAod"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=['id','user_id','quiz_id','submitted_at','created_at','updated_at','type','response_map'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTaL6nBiyw-k"
      },
      "source": [
        "# **FEATURE EXTRACTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-wJATU9whMD"
      },
      "source": [
        "**Converting the start and end time into time taken by the student to complete the test and creating a new feature of time consumed by the student in percentage**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G9Xu2uT1mLgL"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "df['started_at'] = pd.to_datetime(df['started_at'], errors='coerce')\n",
        "df['ended_at'] = pd.to_datetime(df['ended_at'], errors='coerce')\n",
        "#Finding the time period in minutes\n",
        "df['time'] = (df['ended_at'] - df['started_at']).dt.total_seconds() / 60\n",
        "#Converting the time period out of total time 15 min into percentage format\n",
        "df['time_taken'] = (df['time']/15)*100\n",
        "df.drop(columns=['started_at','ended_at','time','duration'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwICHSxrw-eI"
      },
      "source": [
        "**The given accuracy is not relavant to the final score of the students so the accuracy column is updated using final score and score details provided**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3leT-Y5BquFN"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=['accuracy'],axis=1,inplace=True)\n",
        "df['final_score'] = pd.to_numeric(df['final_score'], errors='coerce').astype('Int64')\n",
        "df['accuracy']=(df['final_score']/df['score'])*100\n",
        "df.drop(columns=['final_score','score'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbAp6HatxQqe"
      },
      "source": [
        "**The rank is converted in nummerical format**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RWhRiLXRtu26"
      },
      "outputs": [],
      "source": [
        "df['rank'] = df['rank_text'].str.extract(r'#([-\\d]+)').astype(int).abs()\n",
        "df.drop(columns=['rank_text'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oK4Zj8Y22iXA"
      },
      "outputs": [],
      "source": [
        "df['title'] = df['quiz'].apply(lambda x: x['title'] if isinstance(x, dict) else None)\n",
        "df['topic'] = df['quiz'].apply(lambda x: x['topic'] if isinstance(x, dict) else None)\n",
        "df.drop(columns=['quiz'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsGHsXAc7GKV"
      },
      "source": [
        "**processing model for weak areas analysis of students**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwvY3yTrx8_e",
        "outputId": "47400563-0a85-4535-b222-9d3e3f0ceaf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         correct_answers  incorrect_answers  mistakes_corrected\n",
            "cluster                                                        \n",
            "0               8.333333               12.0            0.000000\n",
            "1              15.400000                0.8            1.600000\n",
            "2              28.000000                2.0           10.666667\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "weak_areas = df[['correct_answers', 'incorrect_answers', 'mistakes_corrected']]\n",
        "\n",
        "# Initialize and fit KMeans\n",
        "kmeans_weak = KMeans(n_clusters=3, random_state=42)\n",
        "weak_areas['cluster'] = kmeans_weak.fit_predict(weak_areas)\n",
        "\n",
        "# Analyze clusters\n",
        "print(weak_areas.groupby('cluster').mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**processing model for areas of improvements analysis of students**"
      ],
      "metadata": {
        "id": "lBw_1tnbZC9F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgNGpqjoC0_q",
        "outputId": "57e9df31-1592-4d9f-dccc-af3487b3016f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          accuracy         rank\n",
            "cluster                        \n",
            "0        72.261905  2051.000000\n",
            "1        98.381696  7149.500000\n",
            "2        87.889282   296.666667\n"
          ]
        }
      ],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "improvements = df[['accuracy', 'rank']]\n",
        "\n",
        "# Fit Gaussian Mixture Model\n",
        "gmm_improvements = GaussianMixture(n_components=3, random_state=42)\n",
        "improvements['cluster'] = gmm_improvements.fit_predict(improvements)\n",
        "\n",
        "# Analyze clusters\n",
        "print(improvements.groupby('cluster').mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**processing model for finding performance gap of students**"
      ],
      "metadata": {
        "id": "4PuiToWnZIUP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3OmGohPCZcT",
        "outputId": "44fff16d-34b8-4b3d-9ba3-314178f88168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         negative_score  initial_mistake_count  total_questions    rank\n",
            "cluster                                                                \n",
            "0                   7.7                    9.8             67.1  1524.7\n",
            "1                  1.25                    6.0             26.5  7149.5\n"
          ]
        }
      ],
      "source": [
        "performance_gaps = df[['negative_score', 'initial_mistake_count', 'total_questions', 'rank']]\n",
        "\n",
        "performance_gaps['negative_score']=pd.to_numeric(df['negative_score'], errors='coerce').astype('Int64')\n",
        "kmeans_pg = KMeans(n_clusters=2, random_state=42)\n",
        "performance_gaps['cluster'] = kmeans_pg.fit_predict(performance_gaps)\n",
        "# Analyze clusters\n",
        "print(performance_gaps.groupby('cluster').mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**processing model for recomendations of students**"
      ],
      "metadata": {
        "id": "qV4Fm_hoZOf-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5YXw7QOFOJM",
        "outputId": "1f1e9142-13e5-4882-fc0e-3ba1a46f348a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         better_than  trophy_level\n",
            "cluster                           \n",
            "0              29.75          2.75\n",
            "1             331.50          2.00\n",
            "2             132.50          2.00\n"
          ]
        }
      ],
      "source": [
        "# Select features\n",
        "recommendations = df[['better_than', 'trophy_level']]\n",
        "\n",
        "# Fit DBSCAN\n",
        "model_recommendations = GaussianMixture(n_components=3, random_state=42)\n",
        "recommendations['cluster'] = model_recommendations.fit_predict(recommendations)\n",
        "\n",
        "# Analyze clusters\n",
        "print(recommendations.groupby('cluster').mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**processing model for student persona of students**"
      ],
      "metadata": {
        "id": "2N2XhoFqZSxi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcbUApLQDBtA",
        "outputId": "084c3905-93d3-4439-aac2-9b045c031446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             speed         rank    source\n",
            "cluster                                  \n",
            "0        92.857143  2051.000000  0.428571\n",
            "1            95.25  7149.500000  0.250000\n",
            "2            100.0   296.666667  0.333333\n"
          ]
        }
      ],
      "source": [
        "student_persona = df[['speed', 'rank', 'source']]\n",
        "\n",
        "# Encode categorical data if present\n",
        "student_persona['source'] = student_persona['source'].astype('category').cat.codes\n",
        "student_persona['speed']=pd.to_numeric(student_persona['speed'], errors='coerce').astype('Int64')\n",
        "# Fit KMeans\n",
        "kmeans_persona = KMeans(n_clusters=3, random_state=42)\n",
        "student_persona['cluster'] = kmeans_persona.fit_predict(student_persona)\n",
        "\n",
        "# Analyze clusters\n",
        "print(student_persona.groupby('cluster').mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the trained model for its deployment**"
      ],
      "metadata": {
        "id": "kOuqveyMZXtU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLzX8UnyIae3",
        "outputId": "131a699a-7ec4-49b7-f79e-bf2d6ba5d9a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved successfully in .pt format!\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Example models (replace with your actual models)\n",
        "models = {\n",
        "    \"weak_areas_model\": kmeans_weak,           # KMeans for Weak Areas\n",
        "    \"improvements_model\": gmm_improvements,   # Gaussian Mixture for Improvements\n",
        "    \"performance_gaps_model\": kmeans_pg,      # KMeans for Performance Gaps\n",
        "    \"recommendations_model\": model_recommendations,  # Agglomerative Clustering for Recommendations\n",
        "    \"student_persona_model\": kmeans_persona   # KMeans for Student Persona\n",
        "}\n",
        "\n",
        "# Save each model as a .pt file\n",
        "for model_name, model in models.items():\n",
        "    file_name = f\"{model_name}.pt\"\n",
        "    with open(file_name, 'wb') as file:\n",
        "        pickle.dump(model, file)\n",
        "\n",
        "print(\"Models saved successfully in .pt format!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}